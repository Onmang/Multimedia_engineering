{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1AX19J2hJ9Y8untsiHV994VNJfsqKpA2R",
      "authorship_tag": "ABX9TyPcEB2q+Uka81vxEhiFYqTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onmang/Multimedia_engineering/blob/master/T20ME022_ex07_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUhfxYZkXGpS"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/resistor_v3.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインポート\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os # ディレクトリ（フォルダ）やファイルを扱うためのライブラリ（本当はPathlibライブラリのほうが良いが難しいので簡単な方で）\n",
        "import glob # ファイル一覧を取得するためのライブラリ\n",
        "import re # 正規表現を使ったパターンマッチング用（ラベルを取得するため）\n",
        "tf.test.gpu_device_name() # GPUの利用確認"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Wycb6owDaOND",
        "outputId": "aafe6c96-a004-4125-8ade-57e70e52a873"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = glob.glob('data/train/*/*.png') # 訓練用画像ファイルの取得（拡張子がpng）\n",
        "valid_list = glob.glob('data/valid/*/*.png') # 検証用画像ファイルの取得\n",
        "classes = sorted(os.listdir('data/train'), key=int) # 教師ラベルの一覧をリストで取得する。\"sorted\"でソートしておく。\n",
        "print(classes) # 取得した抵抗器のラベルを表示。文字列になっている点に注意すること！"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rktTXkRPac7b",
        "outputId": "ff747ac8-b30c-4b62-b157-52fd45398369"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['150', '160', '390', '430', '620', '1600', '1800', '2200', '2400', '3000', '3300', '3600', '5600', '9100']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # テストファイル名のリストをTensor型に変換"
      ],
      "metadata": {
        "id": "AKtssaBXa0jV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # 検証用のファイル名のリストをTensor型に変換\n",
        "\n",
        "# ファイル名から画像データをロードしてNNへ入力できるようにデータを成形する。ついでに教師ラベルも取得する\n",
        "def load_file(files):\n",
        "    ys = [] # ラベル\n",
        "    xs = [] # 入力データ\n",
        "    for f in files:\n",
        "        file = bytes.decode(f.numpy()) # ファイル名はTensor型で保存されているため，文字列型として取得する。\n",
        "        m = re.search(r'/(\\d+)_', file) # 正規表現を使ってファイル名から抵抗値を取得する。\n",
        "        label = m.groups()[0] # 抵抗値を取得しlabelに保存\n",
        "        ys.append(label) # ラベルをラベルリストに追加する\n",
        "        img = cv2.imread(file) # 画像データをカラーで取得。画像サイズは64x64になっているのでここではリサイズしない。\n",
        "        xs.append(img) # データを入力データリストに追加\n",
        "    xs = np.array(xs, dtype=np.float32) / 255. # 正規化してfloat32の行列に変換する\n",
        "    ys = np.array(ys, dtype=np.float32) # ラベルも行列に変換\n",
        "    return xs, ys\n",
        "\n",
        "#\n",
        "# tf.Dataによるtf.Tensor変換\n",
        "#\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # 処理を最適化するためのおまじない（自動チューニング設定）\n",
        "train_ds = train_ds.shuffle(len(train_list)) # 訓練データをシャッフルする。引数にはデータ数を指定すると完全なシャッフルが行われる。len(x_train)は60000。\n",
        "train_ds = train_ds.repeat(1) # 1 epochで使われるデータの回数。1の場合，1epochで1回しか使われない。引数を空欄にすると無限に使われる。\n",
        "train_ds = train_ds.batch(32) # ミニバッチを作る。1バッチ32個のデータ。\n",
        "train_ds = train_ds.map(lambda files: tf.py_function(load_file, [files], Tout=[tf.float32, tf.float32])) # ファイル名から入力ラベルとラベルを取得\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # 訓練中に次のバッチを取り出すための処理。\n",
        "\n",
        "valid_ds = valid_ds.batch(32) # 検証データはシャッフルする必要ないので，バッチ化のみの処理でOK。\n",
        "valid_ds = valid_ds.map(lambda x: tf.py_function(load_file, [x], Tout=[tf.float32, tf.float32]))"
      ],
      "metadata": {
        "id": "2LrAPzNMhlEI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API\n",
        "input = Input(shape=(64, 64, 3), name='input') # 入力層の定義　64×64×3 （カラー画像）\n",
        "h = Conv2D(16, (3, 3), padding='same', activation='relu', name='cnn01')(input)\n",
        "h = MaxPooling2D((2, 2), name='pool01')(h)\n",
        "h = Conv2D(32, (3, 3), padding='same', activation='relu', name='cnn02')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool02')(h)\n",
        "h = Conv2D(64, (3, 3), padding='same', activation='relu', name='cnn03')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool03')(h)\n",
        "h = Conv2D(128, (3, 3), padding='same', activation='relu', name='cnn04')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool04')(h)\n",
        "h = Conv2D(256, (3, 3), padding='valid', activation='relu', name='cnn05')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool05')(h)\n",
        "h = Flatten(name='flatten')(h) # GlobalAveragePoolingでも良い\n",
        "h = Dense(128, activation='relu', name='dense01')(h) # 全結合層の隠れ層のノードは128\n",
        "output = Dense(1, activation='linear', name='output')(h) # 出力層\n",
        "\n",
        "model = Model(inputs=input, outputs=output) # この処理でモデルを実体化する。入力層と出力層を渡すと自動的にネットワークを構築してくれる。\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_oPpXv0jtyh",
        "outputId": "779d430a-2324-4e33-b392-fc2e982f7434"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cnn01 (Conv2D)              (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " pool01 (MaxPooling2D)       (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " cnn02 (Conv2D)              (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " pool02 (MaxPooling2D)       (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " cnn03 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " pool03 (MaxPooling2D)       (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " cnn04 (Conv2D)              (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " pool04 (MaxPooling2D)       (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " cnn05 (Conv2D)              (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " pool05 (MaxPooling2D)       (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense01 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,633\n",
            "Trainable params: 425,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TFのバグでこのように書く\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 訓練の実施\n",
        "model.fit(train_ds, epochs=100, validation_data=valid_ds)"
      ],
      "metadata": {
        "id": "_UX0D7qgmSYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d395e52c-a2f0-4995-930e-0ebee8416476"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "104/104 [==============================] - 8s 34ms/step - loss: 8607782.0000 - mae: 2033.6737 - mse: 8596236.0000 - val_loss: 9464142.0000 - val_mae: 1948.2843 - val_mse: 8758927.0000\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 8603607.0000 - mae: 2037.8622 - mse: 8648091.0000 - val_loss: 9459846.0000 - val_mae: 1947.2626 - val_mse: 8754948.0000\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8599446.0000 - mae: 2034.4623 - mse: 8619108.0000 - val_loss: 9455557.0000 - val_mae: 1946.9871 - val_mse: 8751016.0000\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8595295.0000 - mae: 2031.2500 - mse: 8584905.0000 - val_loss: 9451250.0000 - val_mae: 2112.8855 - val_mse: 9131502.0000\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8591152.0000 - mae: 2032.7273 - mse: 8626671.0000 - val_loss: 9446981.0000 - val_mae: 1944.2003 - val_mse: 8743031.0000\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8587009.0000 - mae: 2026.0442 - mse: 8563778.0000 - val_loss: 9442704.0000 - val_mae: 2177.9165 - val_mse: 9487700.0000\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 8582877.0000 - mae: 2030.8204 - mse: 8596455.0000 - val_loss: 9438423.0000 - val_mae: 2199.2524 - val_mse: 9631635.0000\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8578734.0000 - mae: 2029.4406 - mse: 8611731.0000 - val_loss: 9434140.0000 - val_mae: 1962.0050 - val_mse: 8737714.0000\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8574595.0000 - mae: 2027.0491 - mse: 8582413.0000 - val_loss: 9429864.0000 - val_mae: 2107.7878 - val_mse: 9109986.0000\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 8570461.0000 - mae: 2020.8723 - mse: 8541979.0000 - val_loss: 9425558.0000 - val_mae: 1939.8361 - val_mse: 8723221.0000\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8566335.0000 - mae: 2022.3606 - mse: 8548850.0000 - val_loss: 9421301.0000 - val_mae: 2090.8384 - val_mse: 9036851.0000\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8562212.0000 - mae: 2018.0646 - mse: 8532216.0000 - val_loss: 9417042.0000 - val_mae: 1937.8022 - val_mse: 8715333.0000\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 8558091.0000 - mae: 2024.9471 - mse: 8566701.0000 - val_loss: 9412806.0000 - val_mae: 2602.9910 - val_mse: 14697215.0000\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8553972.0000 - mae: 2020.3488 - mse: 8552407.0000 - val_loss: 9408516.0000 - val_mae: 1955.8834 - val_mse: 8713731.0000\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8549840.0000 - mae: 2020.9698 - mse: 8541652.0000 - val_loss: 9404292.0000 - val_mae: 2340.1370 - val_mse: 10925396.0000\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8545717.0000 - mae: 2017.4484 - mse: 8542195.0000 - val_loss: 9400020.0000 - val_mae: 1932.9841 - val_mse: 8699545.0000\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 4s 33ms/step - loss: 8541602.0000 - mae: 2017.5632 - mse: 8528119.0000 - val_loss: 9395739.0000 - val_mae: 2084.7229 - val_mse: 9011314.0000\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8537487.0000 - mae: 2016.7651 - mse: 8537057.0000 - val_loss: 9391474.0000 - val_mae: 2083.7009 - val_mse: 9007055.0000\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 8533367.0000 - mae: 2015.0623 - mse: 8529662.0000 - val_loss: 9387238.0000 - val_mae: 1964.9451 - val_mse: 8704618.0000\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8529253.0000 - mae: 2013.6053 - mse: 8513039.0000 - val_loss: 9383003.0000 - val_mae: 2185.9966 - val_mse: 9573506.0000\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8525141.0000 - mae: 2013.3419 - mse: 8509042.0000 - val_loss: 9378736.0000 - val_mae: 2050.8374 - val_mse: 8883782.0000\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8521030.0000 - mae: 2019.4233 - mse: 8576418.0000 - val_loss: 9374480.0000 - val_mae: 1947.7240 - val_mse: 8681881.0000\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 8516914.0000 - mae: 2009.1907 - mse: 8496751.0000 - val_loss: 9370230.0000 - val_mae: 1946.7030 - val_mse: 8677906.0000\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8512816.0000 - mae: 2015.0780 - mse: 8540665.0000 - val_loss: 9365997.0000 - val_mae: 2137.1997 - val_mse: 9273868.0000\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8508713.0000 - mae: 2010.6780 - mse: 8510524.0000 - val_loss: 9361731.0000 - val_mae: 2158.5298 - val_mse: 9403630.0000\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 8504612.0000 - mae: 2011.4788 - mse: 8519724.0000 - val_loss: 9357543.0000 - val_mae: 1943.8153 - val_mse: 8666036.0000\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8500524.0000 - mae: 2012.4525 - mse: 8527230.0000 - val_loss: 9353284.0000 - val_mae: 2074.9058 - val_mse: 8968903.0000\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8496426.0000 - mae: 2010.2833 - mse: 8518104.0000 - val_loss: 9349056.0000 - val_mae: 2178.4302 - val_mse: 9537890.0000\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 8492334.0000 - mae: 2007.2377 - mse: 8484285.0000 - val_loss: 9344819.0000 - val_mae: 1921.1056 - val_mse: 8648452.0000\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8488248.0000 - mae: 2005.8073 - mse: 8488583.0000 - val_loss: 9340570.0000 - val_mae: 1954.7506 - val_mse: 8660641.0000\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8484162.0000 - mae: 2004.1862 - mse: 8470858.0000 - val_loss: 9336375.0000 - val_mae: 2176.0203 - val_mse: 9524585.0000\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 8480085.0000 - mae: 2000.1973 - mse: 8453042.0000 - val_loss: 9332130.0000 - val_mae: 2152.8564 - val_mse: 9372890.0000\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8476009.0000 - mae: 2004.7798 - mse: 8480777.0000 - val_loss: 9327921.0000 - val_mae: 2040.2766 - val_mse: 8833750.0000\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8471928.0000 - mae: 1998.1648 - mse: 8442830.0000 - val_loss: 9323723.0000 - val_mae: 2128.8999 - val_mse: 9230423.0000\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8467864.0000 - mae: 2002.5764 - mse: 8487844.0000 - val_loss: 9319516.0000 - val_mae: 2172.8098 - val_mse: 9506892.0000\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 8463791.0000 - mae: 2004.6498 - mse: 8478308.0000 - val_loss: 9315287.0000 - val_mae: 2172.1521 - val_mse: 9502455.0000\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8459714.0000 - mae: 1999.3635 - mse: 8445572.0000 - val_loss: 9311080.0000 - val_mae: 2581.3623 - val_mse: 14570430.0000\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8455649.0000 - mae: 1997.5541 - mse: 8434833.0000 - val_loss: 9306895.0000 - val_mae: 1914.9640 - val_mse: 8613353.0000\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 8451593.0000 - mae: 1998.3306 - mse: 8448403.0000 - val_loss: 9302692.0000 - val_mae: 2036.0829 - val_mse: 8808910.0000\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8447538.0000 - mae: 1999.6802 - mse: 8452114.0000 - val_loss: 9298473.0000 - val_mae: 1947.5017 - val_mse: 8620983.0000\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 8443481.0000 - mae: 1999.4773 - mse: 8462615.0000 - val_loss: 9294254.0000 - val_mae: 2124.2085 - val_mse: 9200135.0000\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 8439415.0000 - mae: 1995.5667 - mse: 8420697.0000 - val_loss: 9290104.0000 - val_mae: 2168.2815 - val_mse: 9476026.0000\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8435369.0000 - mae: 1994.7799 - mse: 8421675.0000 - val_loss: 9285909.0000 - val_mae: 2033.5009 - val_mse: 8792387.0000\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8431320.0000 - mae: 1994.3119 - mse: 8413632.0000 - val_loss: 9281720.0000 - val_mae: 2166.9900 - val_mse: 9467225.0000\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 8427275.0000 - mae: 1995.3308 - mse: 8430090.0000 - val_loss: 9277518.0000 - val_mae: 2121.6311 - val_mse: 9182932.0000\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8423224.0000 - mae: 1992.7302 - mse: 8403434.0000 - val_loss: 9273333.0000 - val_mae: 2031.5630 - val_mse: 8780006.0000\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 8419183.0000 - mae: 1991.6007 - mse: 8399510.0000 - val_loss: 9269150.0000 - val_mae: 2030.9174 - val_mse: 8775887.0000\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 8415141.0000 - mae: 1991.3054 - mse: 8397636.0000 - val_loss: 9264960.0000 - val_mae: 2574.2612 - val_mse: 14512852.0000\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8411101.0000 - mae: 1992.8804 - mse: 8403994.0000 - val_loss: 9260788.0000 - val_mae: 2074.3379 - val_mse: 8939867.0000\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 8407052.0000 - mae: 1990.8185 - mse: 8389185.0000 - val_loss: 9256627.0000 - val_mae: 2073.6953 - val_mse: 8935681.0000\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8403020.0000 - mae: 1990.9205 - mse: 8401926.0000 - val_loss: 9252431.0000 - val_mae: 2058.1426 - val_mse: 8868154.0000\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8398986.0000 - mae: 1988.4431 - mse: 8375898.0000 - val_loss: 9248235.0000 - val_mae: 2161.8206 - val_mse: 9432076.0000\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 8394949.0000 - mae: 1990.2472 - mse: 8396092.0000 - val_loss: 9244080.0000 - val_mae: 2116.4663 - val_mse: 9148558.0000\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8390924.0000 - mae: 1991.6906 - mse: 8413927.0000 - val_loss: 9239908.0000 - val_mae: 2570.3877 - val_mse: 14481548.0000\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8386888.0000 - mae: 1989.5254 - mse: 8392236.0000 - val_loss: 9235753.0000 - val_mae: 1923.6628 - val_mse: 8552158.0000\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 8382862.0000 - mae: 1987.1191 - mse: 8380109.0000 - val_loss: 9231577.0000 - val_mae: 2069.8181 - val_mse: 8910475.0000\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8378843.0000 - mae: 1984.5333 - mse: 8355784.0000 - val_loss: 9227425.0000 - val_mae: 2024.4629 - val_mse: 8734812.0000\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 3s 34ms/step - loss: 8374822.0000 - mae: 1984.1796 - mse: 8352093.5000 - val_loss: 9223252.0000 - val_mae: 2068.5271 - val_mse: 8902098.0000\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8370802.0000 - mae: 1986.1060 - mse: 8370391.0000 - val_loss: 9219105.0000 - val_mae: 2157.3069 - val_mse: 9401492.0000\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8366776.5000 - mae: 1988.3458 - mse: 8403291.0000 - val_loss: 9214943.0000 - val_mae: 1934.5935 - val_mse: 8542329.0000\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 8362756.0000 - mae: 1983.1211 - mse: 8342391.5000 - val_loss: 9210759.0000 - val_mae: 2051.6833 - val_mse: 8826525.0000\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8358743.0000 - mae: 1983.6008 - mse: 8358404.5000 - val_loss: 9206591.0000 - val_mae: 1933.2954 - val_mse: 8534467.0000\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 8354727.5000 - mae: 1984.7261 - mse: 8360714.0000 - val_loss: 9202473.0000 - val_mae: 1903.3582 - val_mse: 8516822.0000\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8350718.5000 - mae: 1985.0304 - mse: 8384952.0000 - val_loss: 9198315.0000 - val_mae: 2109.3638 - val_mse: 9101506.0000\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8346701.0000 - mae: 1984.7319 - mse: 8360791.0000 - val_loss: 9194176.0000 - val_mae: 2019.2963 - val_mse: 8702082.0000\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 8342688.5000 - mae: 1981.8918 - mse: 8357712.5000 - val_loss: 9190012.0000 - val_mae: 2048.4558 - val_mse: 8805800.0000\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 5s 51ms/step - loss: 8338684.5000 - mae: 1980.2773 - mse: 8321986.0000 - val_loss: 9185864.0000 - val_mae: 1915.9102 - val_mse: 8505543.0000\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8334685.0000 - mae: 1982.4792 - mse: 8341915.0000 - val_loss: 9181723.0000 - val_mae: 1929.4236 - val_mse: 8511062.0000\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8330686.5000 - mae: 1977.6945 - mse: 8310731.0000 - val_loss: 9177565.0000 - val_mae: 1914.6160 - val_mse: 8497791.0000\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8326690.0000 - mae: 1981.5353 - mse: 8348069.5000 - val_loss: 9173465.0000 - val_mae: 1899.9003 - val_mse: 8490020.0000\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 8322696.0000 - mae: 1976.8706 - mse: 8305423.0000 - val_loss: 9169317.0000 - val_mae: 2060.1316 - val_mse: 8847824.0000\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8318702.0000 - mae: 1979.3221 - mse: 8337891.0000 - val_loss: 9165186.0000 - val_mae: 1898.1655 - val_mse: 8482308.0000\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 8314707.0000 - mae: 1972.6758 - mse: 8286682.0000 - val_loss: 9161052.0000 - val_mae: 2125.9077 - val_mse: 9195150.0000\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8310722.0000 - mae: 1975.8959 - mse: 8303952.0000 - val_loss: 9156921.0000 - val_mae: 2013.4832 - val_mse: 8665413.0000\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8306736.0000 - mae: 1976.7258 - mse: 8312730.0000 - val_loss: 9152792.0000 - val_mae: 1910.7456 - val_mse: 8474654.0000\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8302746.5000 - mae: 1973.0437 - mse: 8281248.0000 - val_loss: 9148663.0000 - val_mae: 2146.3252 - val_mse: 9327513.0000\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8298763.5000 - mae: 1975.7280 - mse: 8306209.0000 - val_loss: 9144557.0000 - val_mae: 2100.9709 - val_mse: 9046226.0000\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8294781.0000 - mae: 1973.8013 - mse: 8308242.0000 - val_loss: 9140419.0000 - val_mae: 2554.8901 - val_mse: 14357049.0000\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8290795.0000 - mae: 1974.0280 - mse: 8293408.0000 - val_loss: 9136308.0000 - val_mae: 2122.0339 - val_mse: 9169432.0000\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8286818.0000 - mae: 1972.1061 - mse: 8273768.5000 - val_loss: 9132182.0000 - val_mae: 2553.5981 - val_mse: 14346727.0000\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8282846.5000 - mae: 1970.4919 - mse: 8276996.5000 - val_loss: 9128059.0000 - val_mae: 1893.7170 - val_mse: 8448006.0000\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8278875.5000 - mae: 1969.9408 - mse: 8274232.0000 - val_loss: 9123979.0000 - val_mae: 2552.3108 - val_mse: 14336446.0000\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 8274908.0000 - mae: 1966.9122 - mse: 8250448.0000 - val_loss: 9119865.0000 - val_mae: 2119.4534 - val_mse: 9152339.0000\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8270946.5000 - mae: 1968.7878 - mse: 8255901.5000 - val_loss: 9115749.0000 - val_mae: 2051.7388 - val_mse: 8793918.0000\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8266978.5000 - mae: 1972.8142 - mse: 8300343.5000 - val_loss: 9111678.0000 - val_mae: 2118.1660 - val_mse: 9143828.0000\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 8263018.5000 - mae: 1965.8425 - mse: 8241481.0000 - val_loss: 9107526.0000 - val_mae: 1903.6426 - val_mse: 8432386.0000\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8259056.5000 - mae: 1970.2537 - mse: 8279343.5000 - val_loss: 9103471.0000 - val_mae: 1890.7599 - val_mse: 8425295.0000\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8255101.0000 - mae: 1967.9052 - mse: 8271871.5000 - val_loss: 9099352.0000 - val_mae: 2116.2263 - val_mse: 9131015.0000\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 8251138.0000 - mae: 1967.5323 - mse: 8255226.0000 - val_loss: 9095258.0000 - val_mae: 2003.8022 - val_mse: 8604724.0000\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 8247183.0000 - mae: 1966.9558 - mse: 8262801.0000 - val_loss: 9091152.0000 - val_mae: 2032.9628 - val_mse: 8707042.0000\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8243231.0000 - mae: 1966.3301 - mse: 8246542.0000 - val_loss: 9087068.0000 - val_mae: 1897.4387 - val_mse: 8412139.0000\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 8239276.5000 - mae: 1963.5496 - mse: 8227119.0000 - val_loss: 9083003.0000 - val_mae: 2046.5814 - val_mse: 8760965.0000\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 8235334.5000 - mae: 1966.6394 - mse: 8255243.0000 - val_loss: 9078900.0000 - val_mae: 2090.6453 - val_mse: 8978699.0000\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8231382.5000 - mae: 1962.8882 - mse: 8228543.5000 - val_loss: 9074808.0000 - val_mae: 2112.3545 - val_mse: 9105497.0000\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8227432.5000 - mae: 1966.7747 - mse: 8243117.0000 - val_loss: 9070745.0000 - val_mae: 2134.0681 - val_mse: 9245646.0000\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 8223486.5000 - mae: 1963.4611 - mse: 8241839.5000 - val_loss: 9066638.0000 - val_mae: 2543.2744 - val_mse: 14264524.0000\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8219544.5000 - mae: 1964.0651 - mse: 8241477.0000 - val_loss: 9062551.0000 - val_mae: 2110.4163 - val_mse: 9092751.0000\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 8215603.5000 - mae: 1961.7368 - mse: 8222797.0000 - val_loss: 9058464.0000 - val_mae: 2109.7698 - val_mse: 9088501.0000\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 8211671.0000 - mae: 1960.3729 - mse: 8216461.0000 - val_loss: 9054401.0000 - val_mae: 1885.5762 - val_mse: 8380093.5000\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 8207737.0000 - mae: 1957.7439 - mse: 8202655.5000 - val_loss: 9050382.0000 - val_mae: 1894.6194 - val_mse: 8379054.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc7c8238ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価\n",
        "errors = []\n",
        "for file in glob.glob('data/test/*.png'):\n",
        "    m = re.search(r'/(\\d+)_', file) # ちょっと違うパターンの書き方\n",
        "    label = float( m.groups()[0] ) # 実数に変換\n",
        "    img = cv2.imread(file)\n",
        "    img = img.reshape(1, 64, 64, 3)\n",
        "    img = np.float32(img) / 255.\n",
        "    pred = model.predict(img)\n",
        "    estimate = pred[0][0]\n",
        "    error = abs(label - estimate) / label * 100\n",
        "    print(f'Label {label}, Estimate {estimate}, Error Rate: {error}')\n",
        "    errors.append(error)\n",
        "ave = np.average(np.array(errors))\n",
        "print(f'平均誤り率 {ave:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujab8-eEGzrX",
        "outputId": "c565942c-3850-40f9-cfb2-f5025fd8a437"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "Label 2400.0, Estimate 226.0541534423828, Error Rate: 90.58107693990071\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Label 3000.0, Estimate 226.0541534423828, Error Rate: 92.46486155192058\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 620.0, Estimate 226.0541534423828, Error Rate: 63.539652670583415\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Label 160.0, Estimate 226.0541534423828, Error Rate: 41.28384590148926\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Label 1800.0, Estimate 226.0541534423828, Error Rate: 87.44143591986762\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Label 1600.0, Estimate 226.0541534423828, Error Rate: 85.87161540985107\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Label 430.0, Estimate 226.0541534423828, Error Rate: 47.42926664130632\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Label 5600.0, Estimate 226.0541534423828, Error Rate: 95.96331868852887\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Label 390.0, Estimate 226.0541534423828, Error Rate: 42.037396553235176\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Label 9100.0, Estimate 226.0541534423828, Error Rate: 97.51588842371008\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Label 150.0, Estimate 226.0541534423828, Error Rate: 50.70276896158854\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Label 2200.0, Estimate 226.0541534423828, Error Rate: 89.72481120716441\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Label 3300.0, Estimate 226.0541534423828, Error Rate: 93.14987413810961\n",
            "平均誤り率 75.21%\n"
          ]
        }
      ]
    }
  ]
}