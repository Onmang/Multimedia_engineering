{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1AX19J2hJ9Y8untsiHV994VNJfsqKpA2R",
      "authorship_tag": "ABX9TyMjaQALUIGa6l8GAEDQhrt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onmang/Multimedia_engineering/blob/master/T20ME022_ex07_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "中間レポート\n",
        "T20ME022 グエンコンフィ"
      ],
      "metadata": {
        "id": "sTNgGJIAjNiR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUhfxYZkXGpS"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/resistor_v3.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインポート\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os # ディレクトリ（フォルダ）やファイルを扱うためのライブラリ（本当はPathlibライブラリのほうが良いが難しいので簡単な方で）\n",
        "import glob # ファイル一覧を取得するためのライブラリ\n",
        "import re # 正規表現を使ったパターンマッチング用（ラベルを取得するため）\n",
        "from keras.preprocessing import image # keras.preprocessing.image APIを利用する。画像拡張用の関数が用意されている。\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "tf.test.gpu_device_name() # GPUの利用確認"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wycb6owDaOND",
        "outputId": "2d1153ef-489d-4706-b31c-088a80f52320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = glob.glob('data/train/*/*.png') # 訓練用画像ファイルの取得（拡張子がpng）\n",
        "valid_list = glob.glob('data/valid/*/*.png') # 検証用画像ファイルの取得\n",
        "classes = sorted(os.listdir('data/train'), key=int) # 教師ラベルの一覧をリストで取得する。\"sorted\"でソートしておく。\n",
        "print(classes) # 取得した抵抗器のラベルを表示。文字列になっている点に注意すること！"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rktTXkRPac7b",
        "outputId": "f6301639-03c1-4063-e698-b39625bb497c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['150', '160', '390', '430', '620', '1600', '1800', '2200', '2400', '3000', '3300', '3600', '5600', '9100']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像変換するためのクラスをセットアップ\n",
        "# あまりドラスティックに変えるとはみ出るのでそこそこにする\n",
        "# ImageDataGeneratorを利用\n",
        "generator = ImageDataGenerator(\n",
        "            rotation_range=90,       # 画像の回転\n",
        "            width_shift_range=0.1,    # 横方向シフト （3通りの方法あり）\n",
        "            height_shift_range=0.1,    # 縦方向シフト\n",
        "            zoom_range=[0.5, 1.0],     # ズーム\n",
        "            horizontal_flip=True,   # 横方向のフラップ（折返し）\n",
        "            vertical_flip=True,      # 縦方向のフラップ\n",
        "            fill_mode='nearest',\n",
        "            )"
      ],
      "metadata": {
        "id": "wikVQ979wXVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ拡張処理と保存\n",
        "# 拡張したデータはオリジナル画像と同じフォルダに保存されるが，拡張子は jpg にしてある（区別するため）\n",
        "# Albumentationを使う場合はソースコードを修正する必要がある。\n",
        "for file in train_list:\n",
        "    dir = os.path.dirname(file) # ファイルパス（ファイルが保存されているフォルダ）を取得\n",
        "    base = os.path.basename(file).split('.')[0] # ファイル名を取得（拡張子なし）\n",
        "    max_img_num = 10 # 1つの画像あたり10倍に拡張\n",
        "    img = cv2.imread(file) # 画像を読み込み\n",
        "    img = img[np.newaxis,:] # 4次元テンソルに変換\n",
        "    id = 0\n",
        "    for d in generator.flow(img, batch_size=1): # flow関数で画像をランダムに変換する\n",
        "        ofile = f'{base}_A{id:03d}.jpg' # 生成した画像はjpgで保存\n",
        "        output = os.path.join(dir, ofile) # 保存するファイル名を設定（ディレクトリ情報付き）\n",
        "        cv2.imwrite(output, d[0, :])  # ファイルに保存\n",
        "        print(f'{output} saved.')\n",
        "        id += 1\n",
        "        # flow関数は無限ループするので必要な枚数生成できたらループを抜ける\n",
        "        if (id % max_img_num) == 0:\n",
        "            break"
      ],
      "metadata": {
        "id": "kKo0DYLWwm6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # 検証用のファイル名のリストをTensor型に変換\n",
        "\n",
        "# ファイル名から画像データをロードしてNNへ入力できるようにデータを成形する。ついでに教師ラベルも取得する\n",
        "def load_file(files):\n",
        "    ys = [] # ラベル\n",
        "    xs = [] # 入力データ\n",
        "    for f in files:\n",
        "        file = bytes.decode(f.numpy()) # ファイル名はTensor型で保存されているため，文字列型として取得する。\n",
        "        m = re.search(r'/(\\d+)_', file) # 正規表現を使ってファイル名から抵抗値を取得する。\n",
        "        label = m.groups()[0] # 抵抗値を取得しlabelに保存\n",
        "        ys.append(label) # ラベルをラベルリストに追加する\n",
        "        img = cv2.imread(file) # 画像データをカラーで取得。画像サイズは64x64になっているのでここではリサイズしない。\n",
        "        xs.append(img) # データを入力データリストに追加\n",
        "    xs = np.array(xs, dtype=np.float32) / 255. # 正規化してfloat32の行列に変換する\n",
        "    ys = np.array(ys, dtype=np.float32) # ラベルも行列に変換\n",
        "    return xs, ys\n",
        "\n",
        "#\n",
        "# tf.Dataによるtf.Tensor変換\n",
        "#\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # 処理を最適化するためのおまじない（自動チューニング設定）\n",
        "train_ds = train_ds.shuffle(len(train_list)) # 訓練データをシャッフルする。引数にはデータ数を指定すると完全なシャッフルが行われる。len(x_train)は60000。\n",
        "train_ds = train_ds.repeat(1) # 1 epochで使われるデータの回数。1の場合，1epochで1回しか使われない。引数を空欄にすると無限に使われる。\n",
        "train_ds = train_ds.batch(32) # ミニバッチを作る。1バッチ32個のデータ。\n",
        "train_ds = train_ds.map(lambda files: tf.py_function(load_file, [files], Tout=[tf.float32, tf.float32])) # ファイル名から入力ラベルとラベルを取得\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # 訓練中に次のバッチを取り出すための処理。\n",
        "\n",
        "valid_ds = valid_ds.batch(32) # 検証データはシャッフルする必要ないので，バッチ化のみの処理でOK。\n",
        "valid_ds = valid_ds.map(lambda x: tf.py_function(load_file, [x], Tout=[tf.float32, tf.float32]))"
      ],
      "metadata": {
        "id": "2LrAPzNMhlEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API\n",
        "input = Input(shape=(64, 64, 3), name='input') # 入力層の定義　64×64×3 （カラー画像）\n",
        "h = Conv2D(16, (3, 3), padding='same', activation='relu', name='cnn01')(input)\n",
        "h = MaxPooling2D((2, 2), name='pool01')(h)\n",
        "h = Conv2D(64, (3, 3), padding='same', activation='relu', name='cnn02')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool02')(h)\n",
        "h = Conv2D(128, (3, 3), padding='same', activation='relu', name='cnn03')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool03')(h)\n",
        "h = Conv2D(256, (3, 3), padding='same', activation='relu', name='cnn04')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool04')(h)\n",
        "h = Conv2D(512, (3, 3), padding='valid', activation='relu', name='cnn05')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool05')(h)\n",
        "h = Flatten(name='flatten')(h) # GlobalAveragePoolingでも良い\n",
        "h = Dense(128, activation='relu', name='dense01')(h) # 全結合層の隠れ層のノードは128\n",
        "output = Dense(1, activation='linear', name='output')(h) # 出力層\n",
        "\n",
        "model = Model(inputs=input, outputs=output) # この処理でモデルを実体化する。入力層と出力層を渡すと自動的にネットワークを構築してくれる。\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_oPpXv0jtyh",
        "outputId": "08b3bad3-166b-4303-d4e7-3f2e0e327153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cnn01 (Conv2D)              (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " pool01 (MaxPooling2D)       (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " cnn02 (Conv2D)              (None, 32, 32, 64)        9280      \n",
            "                                                                 \n",
            " pool02 (MaxPooling2D)       (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " cnn03 (Conv2D)              (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " pool03 (MaxPooling2D)       (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " cnn04 (Conv2D)              (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " pool04 (MaxPooling2D)       (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " cnn05 (Conv2D)              (None, 2, 2, 512)         1180160   \n",
            "                                                                 \n",
            " pool05 (MaxPooling2D)       (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense01 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,624,705\n",
            "Trainable params: 1,624,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TFのバグでこのように書く\n",
        "\n",
        "#model.compile(optimizer='adam', loss='MSE', metrics=['MAE'])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), loss='MSE', metrics=['MAE'])\n",
        "# 訓練の実施\n",
        "model.fit(train_ds, epochs=40, validation_data=valid_ds)"
      ],
      "metadata": {
        "id": "_UX0D7qgmSYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbcd4514-db72-4609-c230-3f2c27b1c98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "104/104 [==============================] - 8s 38ms/step - loss: 5405941.5000 - MAE: 1687.9373 - val_loss: 5455968.5000 - val_MAE: 1558.8451\n",
            "Epoch 2/40\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 4655428.5000 - MAE: 1576.8140 - val_loss: 5104841.5000 - val_MAE: 1577.6837\n",
            "Epoch 3/40\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 4457936.5000 - MAE: 1551.9526 - val_loss: 5185103.0000 - val_MAE: 1502.8705\n",
            "Epoch 4/40\n",
            "104/104 [==============================] - 5s 44ms/step - loss: 4396876.0000 - MAE: 1486.1680 - val_loss: 3925983.5000 - val_MAE: 1467.2157\n",
            "Epoch 5/40\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 2721175.2500 - MAE: 1114.7229 - val_loss: 1591818.5000 - val_MAE: 832.7247\n",
            "Epoch 6/40\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 1374411.3750 - MAE: 795.8090 - val_loss: 1250728.7500 - val_MAE: 751.9219\n",
            "Epoch 7/40\n",
            "104/104 [==============================] - 6s 53ms/step - loss: 1000826.1875 - MAE: 675.7651 - val_loss: 1004665.9375 - val_MAE: 666.3290\n",
            "Epoch 8/40\n",
            "104/104 [==============================] - 5s 44ms/step - loss: 703236.3125 - MAE: 558.8447 - val_loss: 740727.4375 - val_MAE: 626.3000\n",
            "Epoch 9/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 542680.4375 - MAE: 483.8840 - val_loss: 655108.0000 - val_MAE: 476.9678\n",
            "Epoch 10/40\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 295436.1875 - MAE: 350.6335 - val_loss: 243585.1250 - val_MAE: 278.0477\n",
            "Epoch 11/40\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 199368.9688 - MAE: 288.2673 - val_loss: 237091.2031 - val_MAE: 289.4406\n",
            "Epoch 12/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 173047.9062 - MAE: 264.0436 - val_loss: 200803.2188 - val_MAE: 339.7903\n",
            "Epoch 13/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 107893.7344 - MAE: 212.4456 - val_loss: 172633.7812 - val_MAE: 324.7253\n",
            "Epoch 14/40\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 88868.3750 - MAE: 190.1252 - val_loss: 96156.9219 - val_MAE: 237.8881\n",
            "Epoch 15/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 79490.2734 - MAE: 184.2252 - val_loss: 122495.7422 - val_MAE: 204.7804\n",
            "Epoch 16/40\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 94772.3594 - MAE: 190.6256 - val_loss: 88001.1250 - val_MAE: 178.2208\n",
            "Epoch 17/40\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 67787.5547 - MAE: 166.1241 - val_loss: 142033.0938 - val_MAE: 242.3617\n",
            "Epoch 18/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 97264.5234 - MAE: 197.4608 - val_loss: 86507.9688 - val_MAE: 177.6968\n",
            "Epoch 19/40\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 46163.3438 - MAE: 135.7943 - val_loss: 120039.7422 - val_MAE: 212.9892\n",
            "Epoch 20/40\n",
            "104/104 [==============================] - 5s 45ms/step - loss: 37643.5664 - MAE: 124.5818 - val_loss: 87248.1250 - val_MAE: 241.7110\n",
            "Epoch 21/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 39715.4180 - MAE: 127.0669 - val_loss: 56589.4609 - val_MAE: 129.2064\n",
            "Epoch 22/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 52462.5898 - MAE: 144.5162 - val_loss: 128568.3828 - val_MAE: 209.9668\n",
            "Epoch 23/40\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 38117.5859 - MAE: 122.9757 - val_loss: 82629.8906 - val_MAE: 145.1808\n",
            "Epoch 24/40\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 91543.0547 - MAE: 185.0709 - val_loss: 62260.2969 - val_MAE: 198.0956\n",
            "Epoch 25/40\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 29802.8535 - MAE: 109.0166 - val_loss: 88323.5000 - val_MAE: 194.9289\n",
            "Epoch 26/40\n",
            "104/104 [==============================] - 5s 46ms/step - loss: 47114.2109 - MAE: 135.7849 - val_loss: 50770.7930 - val_MAE: 122.2443\n",
            "Epoch 27/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 21764.7441 - MAE: 92.4076 - val_loss: 62905.4336 - val_MAE: 161.2627\n",
            "Epoch 28/40\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 24344.0137 - MAE: 98.6082 - val_loss: 35708.2227 - val_MAE: 106.7585\n",
            "Epoch 29/40\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 21666.1582 - MAE: 92.1624 - val_loss: 46159.8750 - val_MAE: 157.1759\n",
            "Epoch 30/40\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 15138.3447 - MAE: 78.0423 - val_loss: 53721.5938 - val_MAE: 122.3369\n",
            "Epoch 31/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 24335.7480 - MAE: 98.6187 - val_loss: 59048.4258 - val_MAE: 128.4018\n",
            "Epoch 32/40\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 62513.5039 - MAE: 156.6628 - val_loss: 237143.0469 - val_MAE: 258.1407\n",
            "Epoch 33/40\n",
            "104/104 [==============================] - 5s 45ms/step - loss: 75689.5859 - MAE: 174.5430 - val_loss: 73696.8125 - val_MAE: 142.5578\n",
            "Epoch 34/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 34146.5508 - MAE: 115.2929 - val_loss: 38230.1055 - val_MAE: 103.4806\n",
            "Epoch 35/40\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 49918.7070 - MAE: 138.2346 - val_loss: 62205.5859 - val_MAE: 172.0342\n",
            "Epoch 36/40\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 36778.7031 - MAE: 119.2388 - val_loss: 44253.7617 - val_MAE: 133.9848\n",
            "Epoch 37/40\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 46079.6797 - MAE: 131.3675 - val_loss: 70834.1328 - val_MAE: 145.2944\n",
            "Epoch 38/40\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 23804.8770 - MAE: 96.8126 - val_loss: 40992.5781 - val_MAE: 109.3500\n",
            "Epoch 39/40\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 37829.9375 - MAE: 115.8738 - val_loss: 44025.0273 - val_MAE: 104.9404\n",
            "Epoch 40/40\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 14330.9434 - MAE: 73.0538 - val_loss: 31390.6523 - val_MAE: 104.5923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe6d823b640>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価\n",
        "errors = []\n",
        "for file in glob.glob('data/test/*.png'):\n",
        "    m = re.search(r'/(\\d+)_', file) # ちょっと違うパターンの書き方\n",
        "    label = float( m.groups()[0] ) # 実数に変換\n",
        "    img = cv2.imread(file)\n",
        "    img = img.reshape(1, 64, 64, 3)\n",
        "    img = np.float32(img) / 255.\n",
        "    pred = model.predict(img)\n",
        "    estimate = pred[0][0]\n",
        "    error = abs(label - estimate) / label * 100\n",
        "    print(f'Label {label}, Estimate {estimate}, Error Rate: {error}')\n",
        "    errors.append(error)\n",
        "ave = np.average(np.array(errors))\n",
        "print(f'平均誤り率 {ave:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujab8-eEGzrX",
        "outputId": "73987e8e-aa4e-4c0e-9ac8-ace9dd3a88ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "Label 2400.0, Estimate 2357.905029296875, Error Rate: 1.7539571126302085\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 3000.0, Estimate 3250.764892578125, Error Rate: 8.358829752604166\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 620.0, Estimate 628.4247436523438, Error Rate: 1.358829621345766\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Label 160.0, Estimate 180.9312286376953, Error Rate: 13.08201789855957\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Label 1800.0, Estimate 1891.460205078125, Error Rate: 5.081122504340278\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 1600.0, Estimate 1612.178466796875, Error Rate: 0.7611541748046875\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Label 430.0, Estimate 448.8542785644531, Error Rate: 4.384715945221656\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Label 5600.0, Estimate 5796.75244140625, Error Rate: 3.513436453683036\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Label 390.0, Estimate 407.1075134277344, Error Rate: 4.3865419045472755\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Label 9100.0, Estimate 9330.458984375, Error Rate: 2.5325163118131866\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Label 150.0, Estimate 132.9422149658203, Error Rate: 11.371856689453125\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Label 2200.0, Estimate 2234.131591796875, Error Rate: 1.5514359907670454\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 3300.0, Estimate 3395.381591796875, Error Rate: 2.8903512665719697\n",
            "平均誤り率 4.69%\n"
          ]
        }
      ]
    }
  ]
}