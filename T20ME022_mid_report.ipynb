{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onmang/Multimedia_engineering/blob/master/T20ME022_mid_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "中間レポート\n",
        "T20ME022 グエンコンフィ"
      ],
      "metadata": {
        "id": "sTNgGJIAjNiR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XUhfxYZkXGpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac362a9-8fbf-43d6-c37b-433bc56968c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/resistor_v3.zip\n",
            "replace data/valid/1600/1600_230_0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip \"/content/resistor_v3.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインポート\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os # ディレクトリ（フォルダ）やファイルを扱うためのライブラリ（本当はPathlibライブラリのほうが良いが難しいので簡単な方で）\n",
        "import glob # ファイル一覧を取得するためのライブラリ\n",
        "import re # 正規表現を使ったパターンマッチング用（ラベルを取得するため）\n",
        "from keras.preprocessing import image # keras.preprocessing.image APIを利用する。画像拡張用の関数が用意されている。\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "tf.test.gpu_device_name() # GPUの利用確認"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wycb6owDaOND",
        "outputId": "51f48de0-3355-44d4-e4d7-4286a34be6b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = glob.glob('data/train/*/*.png') # 訓練用画像ファイルの取得（拡張子がpng）\n",
        "valid_list = glob.glob('data/valid/*/*.png') # 検証用画像ファイルの取得\n",
        "classes = sorted(os.listdir('data/train'), key=int) # 教師ラベルの一覧をリストで取得する。\"sorted\"でソートしておく。\n",
        "print(classes) # 取得した抵抗器のラベルを表示。文字列になっている点に注意すること！"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rktTXkRPac7b",
        "outputId": "7e9d8c1a-f3fd-432c-cc8f-eb4f9422aa8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['150', '160', '390', '430', '620', '1600', '1800', '2200', '2400', '3000', '3300', '3600', '5600', '9100']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像変換するためのクラスをセットアップ\n",
        "# あまりドラスティックに変えるとはみ出るのでそこそこにする\n",
        "# ImageDataGeneratorを利用\n",
        "generator = ImageDataGenerator(\n",
        "            rotation_range=90,       # 画像の回転\n",
        "            width_shift_range=0.1,    # 横方向シフト （3通りの方法あり）\n",
        "            height_shift_range=0.1,    # 縦方向シフト\n",
        "            zoom_range=[0.8, 1.0],     # ズーム\n",
        "            horizontal_flip=True,   # 横方向のフラップ（折返し）\n",
        "            vertical_flip=True,      # 縦方向のフラップ\n",
        "            fill_mode='nearest',\n",
        "            )"
      ],
      "metadata": {
        "id": "wikVQ979wXVF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ拡張処理と保存\n",
        "# 拡張したデータはオリジナル画像と同じフォルダに保存されるが，拡張子は jpg にしてある（区別するため）\n",
        "# Albumentationを使う場合はソースコードを修正する必要がある。\n",
        "for file in train_list:\n",
        "    dir = os.path.dirname(file) # ファイルパス（ファイルが保存されているフォルダ）を取得\n",
        "    base = os.path.basename(file).split('.')[0] # ファイル名を取得（拡張子なし）\n",
        "    max_img_num = 5 # 1つの画像あたり10倍に拡張\n",
        "    img = cv2.imread(file) # 画像を読み込み\n",
        "    img = img[np.newaxis,:] # 4次元テンソルに変換\n",
        "    id = 0\n",
        "    for d in generator.flow(img, batch_size=1): # flow関数で画像をランダムに変換する\n",
        "        ofile = f'{base}_A{id:03d}.jpg' # 生成した画像はjpgで保存\n",
        "        output = os.path.join(dir, ofile) # 保存するファイル名を設定（ディレクトリ情報付き）\n",
        "        cv2.imwrite(output, d[0, :])  # ファイルに保存\n",
        "        print(f'{output} saved.')\n",
        "        id += 1\n",
        "        # flow関数は無限ループするので必要な枚数生成できたらループを抜ける\n",
        "        if (id % max_img_num) == 0:\n",
        "            break"
      ],
      "metadata": {
        "id": "kKo0DYLWwm6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # 検証用のファイル名のリストをTensor型に変換\n",
        "\n",
        "# ファイル名から画像データをロードしてNNへ入力できるようにデータを成形する。ついでに教師ラベルも取得する\n",
        "def load_file(files):\n",
        "    ys = [] # ラベル\n",
        "    xs = [] # 入力データ\n",
        "    for f in files:\n",
        "        file = bytes.decode(f.numpy()) # ファイル名はTensor型で保存されているため，文字列型として取得する。\n",
        "        m = re.search(r'/(\\d+)_', file) # 正規表現を使ってファイル名から抵抗値を取得する。\n",
        "        label = m.groups()[0] # 抵抗値を取得しlabelに保存\n",
        "        ys.append(label) # ラベルをラベルリストに追加する\n",
        "        img = cv2.imread(file) # 画像データをカラーで取得。画像サイズは64x64になっているのでここではリサイズしない。\n",
        "        xs.append(img) # データを入力データリストに追加\n",
        "    xs = np.array(xs, dtype=np.float32) / 255. # 正規化してfloat32の行列に変換する\n",
        "    ys = np.array(ys, dtype=np.float32) # ラベルも行列に変換\n",
        "    return xs, ys\n",
        "\n",
        "#\n",
        "# tf.Dataによるtf.Tensor変換\n",
        "#\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # 処理を最適化するためのおまじない（自動チューニング設定）\n",
        "train_ds = train_ds.shuffle(len(train_list)) # 訓練データをシャッフルする。引数にはデータ数を指定すると完全なシャッフルが行われる。len(x_train)は60000。\n",
        "train_ds = train_ds.repeat(1) # 1 epochで使われるデータの回数。1の場合，1epochで1回しか使われない。引数を空欄にすると無限に使われる。\n",
        "train_ds = train_ds.batch(64) # ミニバッチを作る。1バッチ32個のデータ。\n",
        "train_ds = train_ds.map(lambda files: tf.py_function(load_file, [files], Tout=[tf.float32, tf.float32])) # ファイル名から入力ラベルとラベルを取得\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # 訓練中に次のバッチを取り出すための処理。\n",
        "\n",
        "valid_ds = valid_ds.batch(64) # 検証データはシャッフルする必要ないので，バッチ化のみの処理でOK。\n",
        "valid_ds = valid_ds.map(lambda x: tf.py_function(load_file, [x], Tout=[tf.float32, tf.float32]))"
      ],
      "metadata": {
        "id": "2LrAPzNMhlEI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API\n",
        "input = Input(shape=(64, 64, 3), name='input') # 入力層の定義　64×64×3 （カラー画像）\n",
        "h = Conv2D(16, (3, 3), padding='same', activation='relu', name='cnn01')(input)\n",
        "h = MaxPooling2D((2, 2), name='pool01')(h)\n",
        "h = Conv2D(32, (3, 3), padding='same', activation='relu', name='cnn02')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool02')(h)\n",
        "h = Dropout(rate=0.2)(h)\n",
        "h = Conv2D(64, (3, 3), padding='same', activation='relu', name='cnn03')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool03')(h)\n",
        "h = Dropout(rate=0.2)(h)\n",
        "h = Conv2D(128, (3, 3), padding='same', activation='relu', name='cnn04')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool04')(h)\n",
        "h = Dropout(rate=0.2)(h)\n",
        "h = Conv2D(256, (3, 3), padding='valid', activation='relu', name='cnn05')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool05')(h)\n",
        "h = Flatten(name='flatten')(h) # GlobalAveragePoolingでも良い\n",
        "h = Dense(128, activation='relu', name='dense01')(h) # 全結合層の隠れ層のノードは128\n",
        "output = Dense(1, activation='linear', name='output')(h) # 出力層\n",
        "\n",
        "model = Model(inputs=input, outputs=output) # この処理でモデルを実体化する。入力層と出力層を渡すと自動的にネットワークを構築してくれる。\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_oPpXv0jtyh",
        "outputId": "0e315d40-2f6a-4d71-9384-9190f09b3977"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cnn01 (Conv2D)              (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " pool01 (MaxPooling2D)       (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " cnn02 (Conv2D)              (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " pool02 (MaxPooling2D)       (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " cnn03 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " pool03 (MaxPooling2D)       (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " cnn04 (Conv2D)              (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " pool04 (MaxPooling2D)       (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " cnn05 (Conv2D)              (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " pool05 (MaxPooling2D)       (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense01 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,633\n",
            "Trainable params: 425,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TFのバグでこのように書く\n",
        "\n",
        "#model.compile(optimizer='adam', loss='MSE', metrics=['MAE'])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002), loss='MSE', metrics=['MAE'])\n",
        "# 訓練の実施\n",
        "model.fit(train_ds, epochs=40, validation_data=valid_ds)"
      ],
      "metadata": {
        "id": "_UX0D7qgmSYq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "outputId": "90d8e557-b925-4733-8789-80c98957822a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "52/52 [==============================] - 7s 73ms/step - loss: 5323212.0000 - MAE: 1679.2743 - val_loss: 5083201.0000 - val_MAE: 1531.8256\n",
            "Epoch 2/40\n",
            "52/52 [==============================] - 3s 60ms/step - loss: 4452913.5000 - MAE: 1551.0417 - val_loss: 5347021.0000 - val_MAE: 1385.6010\n",
            "Epoch 3/40\n",
            "52/52 [==============================] - 3s 60ms/step - loss: 4486718.0000 - MAE: 1551.1445 - val_loss: 5066563.0000 - val_MAE: 1807.0126\n",
            "Epoch 4/40\n",
            "52/52 [==============================] - 3s 66ms/step - loss: 4565300.0000 - MAE: 1577.3650 - val_loss: 5028147.5000 - val_MAE: 1421.8251\n",
            "Epoch 5/40\n",
            "52/52 [==============================] - 3s 61ms/step - loss: 4403099.0000 - MAE: 1541.4844 - val_loss: 4931529.5000 - val_MAE: 1528.2721\n",
            "Epoch 6/40\n",
            "52/52 [==============================] - 3s 58ms/step - loss: 4379899.0000 - MAE: 1542.2500 - val_loss: 4887632.5000 - val_MAE: 1361.6146\n",
            "Epoch 7/40\n",
            "52/52 [==============================] - 4s 71ms/step - loss: 4276384.0000 - MAE: 1517.3660 - val_loss: 4804811.0000 - val_MAE: 1425.1628\n",
            "Epoch 8/40\n",
            "52/52 [==============================] - 3s 61ms/step - loss: 4128868.5000 - MAE: 1464.1447 - val_loss: 4486639.5000 - val_MAE: 1400.1252\n",
            "Epoch 9/40\n",
            "52/52 [==============================] - 3s 57ms/step - loss: 3060584.5000 - MAE: 1189.8053 - val_loss: 2910717.0000 - val_MAE: 952.9691\n",
            "Epoch 10/40\n",
            "52/52 [==============================] - 3s 67ms/step - loss: 2465278.5000 - MAE: 1070.6753 - val_loss: 2117641.7500 - val_MAE: 1210.9799\n",
            "Epoch 11/40\n",
            "52/52 [==============================] - 3s 66ms/step - loss: 1638593.0000 - MAE: 871.8750 - val_loss: 1366061.6250 - val_MAE: 882.7798\n",
            "Epoch 12/40\n",
            "52/52 [==============================] - 3s 57ms/step - loss: 1432133.5000 - MAE: 818.4766 - val_loss: 1331142.6250 - val_MAE: 713.7173\n",
            "Epoch 13/40\n",
            "52/52 [==============================] - 3s 65ms/step - loss: 1294590.1250 - MAE: 778.1752 - val_loss: 1108729.8750 - val_MAE: 614.2631\n",
            "Epoch 14/40\n",
            "52/52 [==============================] - 4s 69ms/step - loss: 977007.5000 - MAE: 676.3467 - val_loss: 836237.3125 - val_MAE: 555.3046\n",
            "Epoch 15/40\n",
            "52/52 [==============================] - 3s 59ms/step - loss: 949792.6250 - MAE: 667.6604 - val_loss: 913131.5000 - val_MAE: 629.4488\n",
            "Epoch 16/40\n",
            "52/52 [==============================] - 3s 59ms/step - loss: 798270.1250 - MAE: 606.9321 - val_loss: 840302.3750 - val_MAE: 625.9077\n",
            "Epoch 17/40\n",
            "52/52 [==============================] - 3s 60ms/step - loss: 795349.8125 - MAE: 606.4638 - val_loss: 1060710.5000 - val_MAE: 615.9945\n",
            "Epoch 18/40\n",
            "27/52 [==============>...............] - ETA: 1s - loss: 741410.0625 - MAE: 584.4741"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cdf4620bab51>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 訓練の実施\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価\n",
        "errors = []\n",
        "for file in glob.glob('data/test/*.png'):\n",
        "    m = re.search(r'/(\\d+)_', file) # ちょっと違うパターンの書き方\n",
        "    label = float( m.groups()[0] ) # 実数に変換\n",
        "    img = cv2.imread(file)\n",
        "    img = img.reshape(1, 64, 64, 3)\n",
        "    img = np.float32(img) / 255.\n",
        "    pred = model.predict(img)\n",
        "    estimate = pred[0][0]\n",
        "    error = abs(label - estimate) / label * 100\n",
        "    print(f'Label {label}, Estimate {estimate}, Error Rate: {error}')\n",
        "    errors.append(error)\n",
        "ave = np.average(np.array(errors))\n",
        "print(f'平均誤り率 {ave:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujab8-eEGzrX",
        "outputId": "05a3aebf-3156-4c8f-c6fe-a5cd2b540546"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step\n",
            "Label 2400.0, Estimate 2840.9033203125, Error Rate: 18.3709716796875\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Label 5600.0, Estimate 5821.91015625, Error Rate: 3.962681361607143\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Label 2200.0, Estimate 2343.614013671875, Error Rate: 6.527909712357954\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Label 390.0, Estimate 339.3863830566406, Error Rate: 12.977850498297276\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Label 1800.0, Estimate 1945.4219970703125, Error Rate: 8.078999837239584\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Label 430.0, Estimate 540.4139404296875, Error Rate: 25.677660565043603\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Label 3300.0, Estimate 3116.620361328125, Error Rate: 5.556958747632576\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Label 3000.0, Estimate 2803.95849609375, Error Rate: 6.534716796874999\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Label 620.0, Estimate 627.36083984375, Error Rate: 1.1872322328629032\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 160.0, Estimate 265.22882080078125, Error Rate: 65.76801300048828\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Label 150.0, Estimate 146.99447631835938, Error Rate: 2.0036824544270835\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Label 9100.0, Estimate 9444.3662109375, Error Rate: 3.7842440762362637\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Label 1600.0, Estimate 1706.4815673828125, Error Rate: 6.65509796142578\n",
            "平均誤り率 12.85%\n"
          ]
        }
      ]
    }
  ]
}