{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1AX19J2hJ9Y8untsiHV994VNJfsqKpA2R",
      "authorship_tag": "ABX9TyPTRutfKOzsj9eFT4aGT6Ou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onmang/Multimedia_engineering/blob/master/T20ME022_ex07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUhfxYZkXGpS"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/resistor_v3.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインポート\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2  \n",
        "import matplotlib.pyplot as plt\n",
        "import os # ディレクトリ（フォルダ）やファイルを扱うためのライブラリ（本当はPathlibライブラリのほうが良いが難しいので簡単な方で）\n",
        "import glob # ファイル一覧を取得するためのライブラリ\n",
        "import re # 正規表現を使ったパターンマッチング用（ラベルを取得するため）\n",
        "tf.test.gpu_device_name() # GPUの利用確認"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wycb6owDaOND",
        "outputId": "85810694-32a6-4a02-f64d-08e5cd43968b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = glob.glob('data/train/*/*.png') # 訓練用画像ファイルの取得（拡張子がpng）\n",
        "valid_list = glob.glob('data/valid/*/*.png') # 検証用画像ファイルの取得\n",
        "classes = sorted(os.listdir('data/train'), key=int) # 教師ラベルの一覧をリストで取得する。\"sorted\"でソートしておく。\n",
        "print(classes) # 取得した抵抗器のラベルを表示。文字列になっている点に注意すること！"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rktTXkRPac7b",
        "outputId": "b4b3e621-520c-47ad-e8e1-91f223ee8f90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['150', '160', '390', '430', '620', '1600', '1800', '2200', '2400', '3000', '3300', '3600', '5600', '9100']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # テストファイル名のリストをTensor型に変換"
      ],
      "metadata": {
        "id": "AKtssaBXa0jV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # 検証用のファイル名のリストをTensor型に変換\n",
        "\n",
        "# ファイル名から画像データをロードしてNNへ入力できるようにデータを成形する。ついでに教師ラベルも取得する\n",
        "def load_file(files):\n",
        "    ys = [] # ラベル\n",
        "    xs = [] # 入力データ\n",
        "    for f in files:        \n",
        "        file = bytes.decode(f.numpy()) # ファイル名はTensor型で保存されているため，文字列型として取得する。\n",
        "        m = re.search(r'/(\\d+)_', file) # 正規表現を使ってファイル名から抵抗値を取得する。\n",
        "        label = m.groups()[0] # 抵抗値を取得しlabelに保存\n",
        "        ys.append(classes.index(label)) # ラベルをラベルIDに変換してラベルリストに追加する\n",
        "        #print(f'resistor = {label}, index={classes.index(label)}')\n",
        "        img = cv2.imread(file) # 画像データをカラーで取得。画像サイズは64x64になっているのでここではリサイズしない。\n",
        "        xs.append(img) # データを入力データリストに追加\n",
        "    xs = np.array(xs, dtype=np.float32) / 255. # 正規化してfloat32の行列に変換する\n",
        "    ys = np.array(ys, dtype=np.int32) # ラベルも行列に変換\n",
        "    return xs, ys\n",
        "\n",
        "#\n",
        "# tf.Dataによるtf.Tensor変換      \n",
        "#\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # 処理を最適化するためのおまじない（自動チューニング設定）\n",
        "train_ds = train_ds.shuffle(len(train_list)) # 訓練データをシャッフルする。引数にはデータ数を指定すると完全なシャッフルが行われる。len(x_train)は60000。\n",
        "train_ds = train_ds.repeat(1) # 1 epochで使われるデータの回数。1の場合，1epochで1回しか使われない。引数を空欄にすると無限に使われる。\n",
        "train_ds = train_ds.batch(32) # ミニバッチを作る。1バッチ32個のデータ。\n",
        "train_ds = train_ds.map(lambda files: tf.py_function(load_file, [files], Tout=[tf.float32, tf.int32])) # ファイル名から入力ラベルとラベルを取得\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # 訓練中に次のバッチを取り出すための処理。\n",
        "\n",
        "valid_ds = valid_ds.batch(32) # 検証データはシャッフルする必要ないので，バッチ化のみの処理でOK。\n",
        "valid_ds = valid_ds.map(lambda x: tf.py_function(load_file, [x], Tout=[tf.float32, tf.int32]))"
      ],
      "metadata": {
        "id": "xJnXd0nlbBI-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API\n",
        "input = Input(shape=(64, 64, 3), name='input') # 入力層の定義　64×64×3 （カラー画像）\n",
        "h = Conv2D(16, (3, 3), padding='same', activation='relu', name='cnn01')(input)\n",
        "h = MaxPooling2D((2, 2), name='pool01')(h)\n",
        "h = Conv2D(32, (3, 3), padding='same', activation='relu', name='cnn02')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool02')(h)\n",
        "h = Conv2D(64, (3, 3), padding='same', activation='relu', name='cnn03')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool03')(h)\n",
        "h = Conv2D(128, (3, 3), padding='same', activation='relu', name='cnn04')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool04')(h)\n",
        "h = Conv2D(256, (3, 3), padding='valid', activation='relu', name='cnn05')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool05')(h)\n",
        "h = Flatten(name='flatten')(h) # GlobalAveragePoolingでも良い\n",
        "h = Dense(128, activation='relu', name='dense01')(h) # 全結合層の隠れ層のノードは128\n",
        "output = Dense(len(classes), activation='softmax', name='output')(h) # 出力層\n",
        "\n",
        "model = Model(inputs=input, outputs=output) # この処理でモデルを実体化する。入力層と出力層を渡すと自動的にネットワークを構築してくれる。\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbW7xw48ffFn",
        "outputId": "c81c989e-c7b5-4320-f922-5bb455f3dda8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cnn01 (Conv2D)              (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " pool01 (MaxPooling2D)       (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " cnn02 (Conv2D)              (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " pool02 (MaxPooling2D)       (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " cnn03 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " pool03 (MaxPooling2D)       (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " cnn04 (Conv2D)              (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " pool04 (MaxPooling2D)       (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " cnn05 (Conv2D)              (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " pool05 (MaxPooling2D)       (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense01 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 14)                1806      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 427,310\n",
            "Trainable params: 427,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TFのバグでこのように書く\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 訓練の実施\n",
        "model.fit(train_ds, epochs=10, validation_data=valid_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CfDvjgBf5NL",
        "outputId": "996add3a-448b-4c42-d4ab-eb6785a28737"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 18s 35ms/step - loss: 2.0099 - sparse_categorical_accuracy: 0.2871 - val_loss: 1.2282 - val_sparse_categorical_accuracy: 0.5143\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 1.0111 - sparse_categorical_accuracy: 0.6185 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.7039\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.3806 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.1281 - val_sparse_categorical_accuracy: 0.9662\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 0.1394 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.0641 - val_sparse_categorical_accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 0.9922\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.0420 - val_sparse_categorical_accuracy: 0.9870\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.0229 - val_sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.0142 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0015 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9979 - val_loss: 6.4238e-04 - val_sparse_categorical_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5ebd672e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 推論のテスト\n",
        "img = cv2.imread('data/valid/3000/3000_200_0.png')\n",
        "img = img.reshape(1, 64, 64, 3)\n",
        "img = np.float32(img) / 255.\n",
        "pred = model.predict(img)\n",
        "print(f'{pred.argmax()} --> {classes[pred.argmax()]} ohm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyt3Tnw7f84F",
        "outputId": "9a54c1ff-2844-42f4-aca6-dcb08799ddd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 117ms/step\n",
            "9 --> 3000 ohm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここから、回帰モデル"
      ],
      "metadata": {
        "id": "H0wzlmfVhQw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(train_list) # 訓練ファイル名のリストをTensor型に変換\n",
        "valid_ds = tf.data.Dataset.list_files(valid_list) # 検証用のファイル名のリストをTensor型に変換\n",
        "\n",
        "# ファイル名から画像データをロードしてNNへ入力できるようにデータを成形する。ついでに教師ラベルも取得する\n",
        "def load_file(files):\n",
        "    ys = [] # ラベル\n",
        "    xs = [] # 入力データ\n",
        "    for f in files:        \n",
        "        file = bytes.decode(f.numpy()) # ファイル名はTensor型で保存されているため，文字列型として取得する。\n",
        "        m = re.search(r'/(\\d+)_', file) # 正規表現を使ってファイル名から抵抗値を取得する。\n",
        "        label = m.groups()[0] # 抵抗値を取得しlabelに保存\n",
        "        ys.append(label) # ラベルをラベルリストに追加する\n",
        "        img = cv2.imread(file) # 画像データをカラーで取得。画像サイズは64x64になっているのでここではリサイズしない。\n",
        "        xs.append(img) # データを入力データリストに追加\n",
        "    xs = np.array(xs, dtype=np.float32) / 255. # 正規化してfloat32の行列に変換する\n",
        "    ys = np.array(ys, dtype=np.float32) # ラベルも行列に変換\n",
        "    return xs, ys\n",
        "\n",
        "#\n",
        "# tf.Dataによるtf.Tensor変換      \n",
        "#\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # 処理を最適化するためのおまじない（自動チューニング設定）\n",
        "train_ds = train_ds.shuffle(len(train_list)) # 訓練データをシャッフルする。引数にはデータ数を指定すると完全なシャッフルが行われる。len(x_train)は60000。\n",
        "train_ds = train_ds.repeat(1) # 1 epochで使われるデータの回数。1の場合，1epochで1回しか使われない。引数を空欄にすると無限に使われる。\n",
        "train_ds = train_ds.batch(32) # ミニバッチを作る。1バッチ32個のデータ。\n",
        "train_ds = train_ds.map(lambda files: tf.py_function(load_file, [files], Tout=[tf.float32, tf.float32])) # ファイル名から入力ラベルとラベルを取得\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE) # 訓練中に次のバッチを取り出すための処理。\n",
        "\n",
        "valid_ds = valid_ds.batch(32) # 検証データはシャッフルする必要ないので，バッチ化のみの処理でOK。\n",
        "valid_ds = valid_ds.map(lambda x: tf.py_function(load_file, [x], Tout=[tf.float32, tf.float32]))"
      ],
      "metadata": {
        "id": "2LrAPzNMhlEI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API\n",
        "input = Input(shape=(64, 64, 3), name='input') # 入力層の定義　64×64×3 （カラー画像）\n",
        "h = Conv2D(16, (3, 3), padding='same', activation='relu', name='cnn01')(input)\n",
        "h = MaxPooling2D((2, 2), name='pool01')(h)\n",
        "h = Conv2D(32, (3, 3), padding='same', activation='relu', name='cnn02')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool02')(h)\n",
        "h = Conv2D(64, (3, 3), padding='same', activation='relu', name='cnn03')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool03')(h)\n",
        "h = Conv2D(128, (3, 3), padding='same', activation='relu', name='cnn04')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool04')(h)\n",
        "h = Conv2D(256, (3, 3), padding='valid', activation='relu', name='cnn05')(h)\n",
        "h = MaxPooling2D((2, 2), name='pool05')(h)\n",
        "h = Flatten(name='flatten')(h) # GlobalAveragePoolingでも良い\n",
        "h = Dense(128, activation='relu', name='dense01')(h) # 全結合層の隠れ層のノードは128\n",
        "output = Dense(1, activation='linear', name='output')(h) # 出力層\n",
        "\n",
        "model = Model(inputs=input, outputs=output) # この処理でモデルを実体化する。入力層と出力層を渡すと自動的にネットワークを構築してくれる。\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_oPpXv0jtyh",
        "outputId": "4583b24c-f9c2-4af2-813d-cc0055e9ace2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cnn01 (Conv2D)              (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " pool01 (MaxPooling2D)       (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " cnn02 (Conv2D)              (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " pool02 (MaxPooling2D)       (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " cnn03 (Conv2D)              (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " pool03 (MaxPooling2D)       (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " cnn04 (Conv2D)              (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " pool04 (MaxPooling2D)       (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " cnn05 (Conv2D)              (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " pool05 (MaxPooling2D)       (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense01 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,633\n",
            "Trainable params: 425,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TFのバグでこのように書く\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 訓練の実施\n",
        "model.fit(train_ds, epochs=110, validation_data=valid_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UX0D7qgmSYq",
        "outputId": "ebb98ee6-23cb-4009-adaf-90a26388214a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            "104/104 [==============================] - 8s 45ms/step - loss: 3330.6206 - mae: 31.3082 - mse: 3316.5117 - val_loss: 27042.0078 - val_mae: 46.8574 - val_mse: 25028.1152\n",
            "Epoch 2/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1584.1007 - mae: 24.5186 - mse: 1602.5001 - val_loss: 26782.3145 - val_mae: 63.3818 - val_mse: 24797.7812\n",
            "Epoch 3/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 2398.0847 - mae: 30.8274 - mse: 2394.8215 - val_loss: 42469.4102 - val_mae: 103.4877 - val_mse: 39639.3359\n",
            "Epoch 4/110\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 4570.5547 - mae: 38.1755 - mse: 4550.9336 - val_loss: 20833.7852 - val_mae: 45.3009 - val_mse: 19281.3887\n",
            "Epoch 5/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1914.2922 - mae: 27.3913 - mse: 1912.7546 - val_loss: 24140.7852 - val_mae: 52.2745 - val_mse: 22343.4082\n",
            "Epoch 6/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 2459.2856 - mae: 31.5297 - mse: 2453.2166 - val_loss: 23963.5352 - val_mae: 50.5695 - val_mse: 22197.3574\n",
            "Epoch 7/110\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 1353.0609 - mae: 24.0894 - mse: 1349.7302 - val_loss: 30802.3379 - val_mae: 50.1487 - val_mse: 28507.5312\n",
            "Epoch 8/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 906.1817 - mae: 19.7621 - mse: 904.0237 - val_loss: 25566.9121 - val_mae: 47.6699 - val_mse: 23694.6055\n",
            "Epoch 9/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 831.9352 - mae: 18.7133 - mse: 829.4203 - val_loss: 30019.0391 - val_mae: 52.6852 - val_mse: 28163.5957\n",
            "Epoch 10/110\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 1847.7593 - mae: 27.5511 - mse: 1841.0222 - val_loss: 34039.9883 - val_mae: 56.9943 - val_mse: 31541.2051\n",
            "Epoch 11/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1708.7279 - mae: 26.7024 - mse: 1710.3518 - val_loss: 30309.5957 - val_mae: 62.2394 - val_mse: 28236.9824\n",
            "Epoch 12/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 5858.8701 - mae: 48.9363 - mse: 5840.5776 - val_loss: 18002.7383 - val_mae: 51.9503 - val_mse: 16670.3418\n",
            "Epoch 13/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 6320.5703 - mae: 49.7824 - mse: 6298.4214 - val_loss: 37277.4062 - val_mae: 57.8058 - val_mse: 34508.1133\n",
            "Epoch 14/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 2237.0461 - mae: 29.0044 - mse: 2232.0874 - val_loss: 25649.7168 - val_mae: 71.2959 - val_mse: 25295.0352\n",
            "Epoch 15/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 2093.2493 - mae: 28.1217 - mse: 2089.2678 - val_loss: 27276.8730 - val_mae: 62.0474 - val_mse: 25461.0859\n",
            "Epoch 16/110\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 1546.4066 - mae: 25.4038 - mse: 1548.0212 - val_loss: 16790.8203 - val_mae: 46.7842 - val_mse: 15592.0850\n",
            "Epoch 17/110\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 1010.4269 - mae: 20.5249 - mse: 1006.5967 - val_loss: 19473.8086 - val_mae: 48.2539 - val_mse: 18075.7988\n",
            "Epoch 18/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 795.7686 - mae: 18.4397 - mse: 795.0554 - val_loss: 25555.4512 - val_mae: 51.3481 - val_mse: 23662.8125\n",
            "Epoch 19/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 645.2496 - mae: 16.9136 - mse: 644.2675 - val_loss: 18404.1387 - val_mae: 43.1533 - val_mse: 17042.3379\n",
            "Epoch 20/110\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 1304.4890 - mae: 23.0083 - mse: 1315.5177 - val_loss: 21193.5781 - val_mae: 50.8602 - val_mse: 19617.2520\n",
            "Epoch 21/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1873.8120 - mae: 28.3607 - mse: 1869.3390 - val_loss: 13448.7686 - val_mae: 47.8801 - val_mse: 12592.1572\n",
            "Epoch 22/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1211.7402 - mae: 22.1869 - mse: 1216.9692 - val_loss: 19371.1250 - val_mae: 49.6410 - val_mse: 18171.1895\n",
            "Epoch 23/110\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 1895.1621 - mae: 29.1164 - mse: 1892.1857 - val_loss: 22606.5059 - val_mae: 60.7201 - val_mse: 21097.0117\n",
            "Epoch 24/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 2849.2349 - mae: 33.0954 - mse: 2838.5073 - val_loss: 18147.7070 - val_mae: 58.5786 - val_mse: 17360.6074\n",
            "Epoch 25/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1311.0273 - mae: 22.5103 - mse: 1314.7571 - val_loss: 29100.2930 - val_mae: 72.7349 - val_mse: 27758.1543\n",
            "Epoch 26/110\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 2503.6345 - mae: 32.7502 - mse: 2495.4546 - val_loss: 23717.7266 - val_mae: 61.1543 - val_mse: 22039.3516\n",
            "Epoch 27/110\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 1534.2706 - mae: 24.2178 - mse: 1529.0530 - val_loss: 16743.7500 - val_mae: 51.3701 - val_mse: 16243.5312\n",
            "Epoch 28/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1832.1349 - mae: 27.4115 - mse: 1827.1049 - val_loss: 26132.9785 - val_mae: 52.2825 - val_mse: 24217.4160\n",
            "Epoch 29/110\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 1411.3844 - mae: 24.1544 - mse: 1439.2511 - val_loss: 18486.9551 - val_mae: 47.3297 - val_mse: 17109.4141\n",
            "Epoch 30/110\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 1216.9500 - mae: 21.9835 - mse: 1211.9718 - val_loss: 17854.2891 - val_mae: 50.7202 - val_mse: 16760.3164\n",
            "Epoch 31/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 633.8199 - mae: 15.9507 - mse: 631.7666 - val_loss: 17636.9004 - val_mae: 47.7477 - val_mse: 16323.4834\n",
            "Epoch 32/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 1312.8481 - mae: 23.2307 - mse: 1340.7115 - val_loss: 22779.9980 - val_mae: 49.2531 - val_mse: 21139.0352\n",
            "Epoch 33/110\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 1136.3878 - mae: 21.4972 - mse: 1134.8553 - val_loss: 23643.5508 - val_mae: 46.3055 - val_mse: 21889.5117\n",
            "Epoch 34/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1044.8088 - mae: 20.4208 - mse: 1046.4711 - val_loss: 24370.3809 - val_mae: 50.3327 - val_mse: 22559.5801\n",
            "Epoch 35/110\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 1342.9902 - mae: 24.8062 - mse: 1337.9620 - val_loss: 24456.1152 - val_mae: 47.3008 - val_mse: 22637.8457\n",
            "Epoch 36/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 2157.0139 - mae: 26.9336 - mse: 2191.3772 - val_loss: 27303.3047 - val_mae: 73.0345 - val_mse: 25578.1562\n",
            "Epoch 37/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 2542.6172 - mae: 31.5100 - mse: 2533.4631 - val_loss: 25319.6719 - val_mae: 51.0219 - val_mse: 23433.5645\n",
            "Epoch 38/110\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 860.7205 - mae: 18.2012 - mse: 857.9138 - val_loss: 20334.5059 - val_mae: 42.8579 - val_mse: 18819.4609\n",
            "Epoch 39/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 792.0559 - mae: 17.8767 - mse: 791.9365 - val_loss: 20154.5957 - val_mae: 46.1125 - val_mse: 18673.0078\n",
            "Epoch 40/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1146.8884 - mae: 21.6399 - mse: 1145.6862 - val_loss: 15642.5781 - val_mae: 42.2407 - val_mse: 14502.3301\n",
            "Epoch 41/110\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 1753.2139 - mae: 27.0314 - mse: 1747.0612 - val_loss: 17892.9238 - val_mae: 44.4190 - val_mse: 16570.2324\n",
            "Epoch 42/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 2932.1643 - mae: 35.3632 - mse: 2921.0439 - val_loss: 30039.1680 - val_mae: 68.3085 - val_mse: 28124.5918\n",
            "Epoch 43/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1703.2886 - mae: 26.2260 - mse: 1700.0009 - val_loss: 23081.6074 - val_mae: 56.4688 - val_mse: 21570.0352\n",
            "Epoch 44/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 819.5676 - mae: 18.2385 - mse: 826.5593 - val_loss: 26239.7090 - val_mae: 48.6012 - val_mse: 24326.7402\n",
            "Epoch 45/110\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 1006.1569 - mae: 20.8735 - mse: 1006.2311 - val_loss: 20757.9805 - val_mae: 46.7561 - val_mse: 19312.3613\n",
            "Epoch 46/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 980.8033 - mae: 19.9282 - mse: 978.8002 - val_loss: 18360.0059 - val_mae: 40.8362 - val_mse: 16992.8164\n",
            "Epoch 47/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 315.1739 - mae: 11.7091 - mse: 316.5880 - val_loss: 19398.2715 - val_mae: 41.4296 - val_mse: 17969.4121\n",
            "Epoch 48/110\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 541.0787 - mae: 15.2842 - mse: 542.4415 - val_loss: 22897.5273 - val_mae: 44.3461 - val_mse: 21216.9082\n",
            "Epoch 49/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 480.5142 - mae: 14.6361 - mse: 484.6686 - val_loss: 23936.1484 - val_mae: 50.2304 - val_mse: 22165.1211\n",
            "Epoch 50/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 17427.4258 - mae: 75.4427 - mse: 17379.0801 - val_loss: 23662.9121 - val_mae: 90.1391 - val_mse: 25699.5508\n",
            "Epoch 51/110\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 7033.5986 - mae: 51.1433 - mse: 7009.3047 - val_loss: 27722.0645 - val_mae: 72.2212 - val_mse: 25829.2070\n",
            "Epoch 52/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1530.8088 - mae: 25.0444 - mse: 1531.0978 - val_loss: 17121.4297 - val_mae: 49.4365 - val_mse: 15967.1084\n",
            "Epoch 53/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1271.2147 - mae: 23.3588 - mse: 1269.9805 - val_loss: 17645.2949 - val_mae: 45.0403 - val_mse: 16331.1553\n",
            "Epoch 54/110\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 1750.5762 - mae: 26.9036 - mse: 1745.3789 - val_loss: 16667.5957 - val_mae: 48.9078 - val_mse: 15993.5361\n",
            "Epoch 55/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1192.4382 - mae: 21.6111 - mse: 1188.5964 - val_loss: 15806.1973 - val_mae: 44.2777 - val_mse: 14641.1201\n",
            "Epoch 56/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 713.1609 - mae: 17.4902 - mse: 710.5339 - val_loss: 16170.9844 - val_mae: 41.8289 - val_mse: 14992.7168\n",
            "Epoch 57/110\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 465.2259 - mae: 14.3469 - mse: 466.0661 - val_loss: 16717.4805 - val_mae: 40.4238 - val_mse: 15472.1895\n",
            "Epoch 58/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 449.1124 - mae: 14.1680 - mse: 447.6302 - val_loss: 17922.4258 - val_mae: 45.2495 - val_mse: 16639.1211\n",
            "Epoch 59/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 336.6182 - mae: 12.4107 - mse: 336.2675 - val_loss: 20148.3691 - val_mae: 44.3539 - val_mse: 18651.5293\n",
            "Epoch 60/110\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 282.9486 - mae: 11.6170 - mse: 282.1517 - val_loss: 17389.6660 - val_mae: 40.9073 - val_mse: 16100.2881\n",
            "Epoch 61/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 388.9058 - mae: 12.9530 - mse: 388.5029 - val_loss: 20110.4473 - val_mae: 46.5368 - val_mse: 18650.7305\n",
            "Epoch 62/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 343.9772 - mae: 12.2915 - mse: 342.9821 - val_loss: 18278.5176 - val_mae: 43.3792 - val_mse: 16959.3477\n",
            "Epoch 63/110\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 275.9506 - mae: 11.1983 - mse: 275.4350 - val_loss: 19222.7422 - val_mae: 42.2982 - val_mse: 17790.7109\n",
            "Epoch 64/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 362.1687 - mae: 12.4612 - mse: 362.0331 - val_loss: 20876.7480 - val_mae: 43.7088 - val_mse: 19322.3027\n",
            "Epoch 65/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 12348.3730 - mae: 63.1540 - mse: 12503.3145 - val_loss: 103278.0781 - val_mae: 160.3331 - val_mse: 95650.4297\n",
            "Epoch 66/110\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 12453.8691 - mae: 67.5402 - mse: 12400.2461 - val_loss: 24560.1836 - val_mae: 57.2987 - val_mse: 22785.7539\n",
            "Epoch 67/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1886.0819 - mae: 27.7072 - mse: 1883.6035 - val_loss: 18857.4453 - val_mae: 83.9624 - val_mse: 33994.7305\n",
            "Epoch 68/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1080.0848 - mae: 22.0021 - mse: 1078.3004 - val_loss: 19208.2305 - val_mae: 49.1778 - val_mse: 18024.0684\n",
            "Epoch 69/110\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 799.5329 - mae: 19.1302 - mse: 803.6099 - val_loss: 19516.6680 - val_mae: 52.0892 - val_mse: 18103.7734\n",
            "Epoch 70/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 545.7629 - mae: 15.3697 - mse: 544.6742 - val_loss: 16036.8350 - val_mae: 40.6793 - val_mse: 14845.3945\n",
            "Epoch 71/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 285.5737 - mae: 11.7295 - mse: 285.3256 - val_loss: 16156.1807 - val_mae: 41.1883 - val_mse: 14953.8535\n",
            "Epoch 72/110\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 334.6017 - mae: 12.3107 - mse: 335.3357 - val_loss: 16792.6699 - val_mae: 41.8844 - val_mse: 15553.5518\n",
            "Epoch 73/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 237.4242 - mae: 10.6287 - mse: 237.3975 - val_loss: 16419.2539 - val_mae: 41.2556 - val_mse: 15217.9336\n",
            "Epoch 74/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 191.9557 - mae: 9.6896 - mse: 191.6914 - val_loss: 17011.5371 - val_mae: 44.1054 - val_mse: 15849.2334\n",
            "Epoch 75/110\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 211.1554 - mae: 10.0734 - mse: 211.0046 - val_loss: 16792.9883 - val_mae: 42.6818 - val_mse: 15580.1191\n",
            "Epoch 76/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 356.6945 - mae: 13.0017 - mse: 355.8854 - val_loss: 18899.9824 - val_mae: 42.0603 - val_mse: 17492.6836\n",
            "Epoch 77/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 278.0542 - mae: 11.3390 - mse: 279.2896 - val_loss: 19818.8418 - val_mae: 42.9359 - val_mse: 18342.1523\n",
            "Epoch 78/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 373.6849 - mae: 12.8159 - mse: 373.2155 - val_loss: 17020.1914 - val_mae: 54.1041 - val_mse: 18080.4434\n",
            "Epoch 79/110\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 463.6159 - mae: 14.1133 - mse: 462.2744 - val_loss: 17371.4277 - val_mae: 40.2554 - val_mse: 16079.6836\n",
            "Epoch 80/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 826.0590 - mae: 18.8286 - mse: 824.0005 - val_loss: 19212.9160 - val_mae: 47.3526 - val_mse: 17782.2129\n",
            "Epoch 81/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 1696.7319 - mae: 24.6964 - mse: 1707.0469 - val_loss: 20464.6035 - val_mae: 65.9852 - val_mse: 18943.0039\n",
            "Epoch 82/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 3649.3425 - mae: 38.9211 - mse: 3638.5923 - val_loss: 20290.9902 - val_mae: 59.4017 - val_mse: 18885.5527\n",
            "Epoch 83/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 2632.2444 - mae: 29.7281 - mse: 2623.4575 - val_loss: 23318.4473 - val_mae: 51.2344 - val_mse: 21594.3730\n",
            "Epoch 84/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 843.2569 - mae: 18.4193 - mse: 841.0010 - val_loss: 16035.7588 - val_mae: 52.9255 - val_mse: 16994.1387\n",
            "Epoch 85/110\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 439.2064 - mae: 13.2412 - mse: 438.2736 - val_loss: 12343.7988 - val_mae: 43.8224 - val_mse: 11734.9834\n",
            "Epoch 86/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 443.0124 - mae: 13.4521 - mse: 445.6818 - val_loss: 15437.1289 - val_mae: 68.3476 - val_mse: 16569.6445\n",
            "Epoch 87/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 5983.8799 - mae: 45.9901 - mse: 5960.5239 - val_loss: 27290.9824 - val_mae: 57.4020 - val_mse: 25268.6836\n",
            "Epoch 88/110\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 1714.2611 - mae: 26.4781 - mse: 1715.2712 - val_loss: 36946.8242 - val_mae: 76.7727 - val_mse: 34228.6602\n",
            "Epoch 89/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 7751.7114 - mae: 56.6418 - mse: 7767.0244 - val_loss: 42010.9961 - val_mae: 130.8963 - val_mse: 43635.2891\n",
            "Epoch 90/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 2543.9851 - mae: 31.8827 - mse: 2542.1965 - val_loss: 19715.0586 - val_mae: 46.6090 - val_mse: 18260.0859\n",
            "Epoch 91/110\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 1131.5990 - mae: 20.6845 - mse: 1129.3429 - val_loss: 18932.9121 - val_mae: 46.0250 - val_mse: 17537.3438\n",
            "Epoch 92/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 542.7139 - mae: 14.4603 - mse: 541.5500 - val_loss: 16983.9297 - val_mae: 44.4514 - val_mse: 16143.2744\n",
            "Epoch 93/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 386.7041 - mae: 12.6968 - mse: 385.2720 - val_loss: 18691.7656 - val_mae: 56.9685 - val_mse: 20704.2832\n",
            "Epoch 94/110\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 403.5689 - mae: 13.2803 - mse: 403.7176 - val_loss: 17828.7500 - val_mae: 41.7494 - val_mse: 16511.0312\n",
            "Epoch 95/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 489.2065 - mae: 14.1016 - mse: 487.4293 - val_loss: 16389.1211 - val_mae: 41.8401 - val_mse: 15233.7070\n",
            "Epoch 96/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1149.0432 - mae: 21.1664 - mse: 1147.8881 - val_loss: 20979.4004 - val_mae: 113.2057 - val_mse: 70669.0078\n",
            "Epoch 97/110\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 740.0225 - mae: 16.5915 - mse: 738.0724 - val_loss: 16879.5605 - val_mae: 43.2122 - val_mse: 15760.3135\n",
            "Epoch 98/110\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 661.6036 - mae: 16.1691 - mse: 661.4057 - val_loss: 23527.2383 - val_mae: 47.6088 - val_mse: 21774.4727\n",
            "Epoch 99/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 500.0445 - mae: 14.5704 - mse: 501.6885 - val_loss: 18644.4023 - val_mae: 41.8068 - val_mse: 17284.1113\n",
            "Epoch 100/110\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 441.0003 - mae: 13.0782 - mse: 439.2017 - val_loss: 20101.3633 - val_mae: 40.6446 - val_mse: 18603.4258\n",
            "Epoch 101/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 343.0798 - mae: 11.8695 - mse: 348.5557 - val_loss: 20179.2148 - val_mae: 48.7417 - val_mse: 18686.6895\n",
            "Epoch 102/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 607.2297 - mae: 15.3323 - mse: 605.2925 - val_loss: 19164.2500 - val_mae: 40.6196 - val_mse: 17741.9492\n",
            "Epoch 103/110\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 1920.4380 - mae: 26.9938 - mse: 1927.8470 - val_loss: 17099.8008 - val_mae: 44.2827 - val_mse: 15830.5742\n",
            "Epoch 104/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1490.5828 - mae: 24.3516 - mse: 1492.1765 - val_loss: 24090.6035 - val_mae: 79.7198 - val_mse: 22858.4023\n",
            "Epoch 105/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 3829.5649 - mae: 40.6353 - mse: 3832.2510 - val_loss: 21122.2695 - val_mae: 54.0432 - val_mse: 19774.4707\n",
            "Epoch 106/110\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 1575.4099 - mae: 25.2842 - mse: 1581.2356 - val_loss: 16086.1338 - val_mae: 65.8057 - val_mse: 18154.7832\n",
            "Epoch 107/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1492.9564 - mae: 24.0682 - mse: 1487.7611 - val_loss: 17559.2246 - val_mae: 41.7030 - val_mse: 16278.6143\n",
            "Epoch 108/110\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1018.2502 - mae: 19.6131 - mse: 1023.8099 - val_loss: 18211.3672 - val_mae: 39.8606 - val_mse: 16855.1562\n",
            "Epoch 109/110\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 463.1460 - mae: 13.4666 - mse: 467.3687 - val_loss: 18735.4473 - val_mae: 44.5853 - val_mse: 17354.5762\n",
            "Epoch 110/110\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1956.4835 - mae: 27.8732 - mse: 1949.4973 - val_loss: 25229.5977 - val_mae: 49.2320 - val_mse: 23369.8086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc50813faf0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 推論のテスト\n",
        "img = cv2.imread('data/valid/3000/3000_200_0.png')\n",
        "img = img.reshape(1, 64, 64, 3)\n",
        "img = np.float32(img) / 255.\n",
        "pred = model.predict(img)\n",
        "print(f'{classes[pred.argmax()]} ohm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MZOlOgz5DLz",
        "outputId": "768afff1-3033-4780-c25c-6d6a81761c3a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc544e10280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "150 ohm\n"
          ]
        }
      ]
    }
  ]
}